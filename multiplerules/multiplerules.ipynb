{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/37/34/f3c3d6bdc3eebf1b6a7c696dd6f934630af6cf5250cec099edf117cd3b53/openai-1.11.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.11.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dar laptops\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/226.1 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/226.1 kB 325.1 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 41.0/226.1 kB 279.3 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 71.7/226.1 kB 391.3 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/226.1 kB 544.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 143.4/226.1 kB 532.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 194.6/226.1 kB 588.9 kB/s eta 0:00:01\n",
      "   -------------------------------------  225.3/226.1 kB 625.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 226.1/226.1 kB 599.6 kB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # it will read from the local env file\n",
    "\n",
    "client : OpenAI = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the world of coding, there lies a notion\n",
      "A concept so powerful, it's like an ocean\n",
      "It's called recursion, a magical spell\n",
      "That allows programs to loop and excel\n",
      "\n",
      "It's a function that can call itself\n",
      "A concept so profound, it's like a stealth\n",
      "It means breaking a problem into smaller parts\n",
      "And calling the function to solve them, it's an art\n",
      "\n",
      "Like a Russian doll, nested within another\n",
      "Recursion can solve problems like no other\n",
      "It's like looking into a mirror, infinite reflections\n",
      "A function that repeats, in endless directions\n",
      "\n",
      "But beware, for recursion can be tricky\n",
      "Too many calls can make a program sticky\n",
      "But if used wisely, it's a powerful tool\n",
      "In the world of coding, it's like a jewel\n",
      "\n",
      "So remember the concept of recursion\n",
      "It's a magical spell, with endless precision\n",
      "Break down problems, loop and repeat\n",
      "In the world of programming, it's truly neat.\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion()->str:\n",
    "    completion : ChatCompletion = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo-1106\",\n",
    "        messages= [\n",
    "            {\n",
    "                # iam defining the system role with the help of content that who you are and how you should have to behave ike \n",
    "                \"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts.\",\n",
    "                # the humman using it is giving the inout through it\n",
    "                \"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(chat_completion())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
